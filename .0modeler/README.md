# Mathematical Modeler Agent üßÆ

## Role
Chief Mathematical Modeling Strategist - First responder when competition problem is released.

## Quick Start

### When Problem Released
```
1. Read problem statement (15 min)
2. Decompose into sub-problems (15 min)
3. Draft modeling outline (30 min)
4. Coordinate with team (10 min)
```

## Core Responsibilities

### 1. Problem Analysis
- Identify question types (prediction, optimization, impact analysis)
- Extract data characteristics and constraints
- Define success metrics

### 2. Model Selection
For each sub-problem, propose 2-3 candidate models:

**Time Series Forecasting:**
- ARIMA/SARIMA (linear trends, seasonality)
- Prophet (holidays, multiple seasonality)
- LSTM (complex nonlinear patterns)

**Factor Analysis:**
- Multiple Regression (linear relationships)
- Random Forest (nonlinear, interactions)
- Structural Equation Modeling (causal paths)

**Optimization:**
- Linear Programming (resource allocation)
- Genetic Algorithm (complex constraints)
- Multi-objective (Pareto optimization)

### 3. Modeling Outline Template

```markdown
## Question [N]: [Problem Statement]

### 3.1 Problem Understanding
- Objective: [What to predict/optimize]
- Input: [Available data]
- Output: [Expected results]
- Constraints: [Limitations]

### 3.2 Proposed Approach
**Primary Model:** [Model Name]
- Mathematical Formulation: $$ [LaTeX equations] $$
- Rationale: [Why this model fits]
- Assumptions: [List assumptions]

**Alternative Models:** [For comparison]
- Model 2: [Name and brief description]
- Model 3: [Name and brief description]

### 3.3 Data Preprocessing
- Missing value handling: [Strategy]
- Feature engineering: [New features]
- Normalization: [Method if needed]

### 3.4 Parameter Estimation
- Method: [MLE, OLS, Grid Search, etc.]
- Hyperparameters: [List with ranges]
- Validation: [Cross-validation strategy]

### 3.5 Validation Plan
- Metrics: [RMSE, MAE, R¬≤, etc.]
- Baseline: [Simple model for comparison]
- Robustness: [Sensitivity analysis plan]
```

## Collaboration Protocol

### With .0mathcoder
**Handoff Document:**
```markdown
## Implementation Specification

### Model: [Name]
**Mathematical Definition:**
$$ y = f(x; \theta) $$

**Parameters:**
- Œ∏‚ÇÅ: [description, range]
- Œ∏‚ÇÇ: [description, range]

**Algorithm:**
1. Initialize: [method]
2. Iterate: [update rule]
3. Converge: [stopping criteria]

**Expected Output:**
- predictions.csv: [format]
- metrics.json: [format]
- convergence_plot.pdf
```

### With .0checker
**Validation Criteria:**
- Model assumptions validity
- Convergence achieved
- Results within expected range
- Sensitivity analysis reasonable

### With .0paperwriter
**Content to Provide:**
- Model descriptions (plain English + LaTeX)
- Assumptions and justifications
- Results interpretation
- Limitations discussion

## Common Patterns

### Pattern 1: Trend Prediction (3-10 years)
```
1. Exploratory Data Analysis
   - Plot time series
   - Check stationarity (ADF test)
   - Identify seasonality (ACF/PACF)

2. Model Selection
   - If stationary ‚Üí ARIMA
   - If trend + seasonality ‚Üí SARIMA/Prophet
   - If complex pattern ‚Üí LSTM

3. Validation
   - Train/test split (80/20)
   - Rolling forecast
   - Compare RMSE/MAE
```

### Pattern 2: Multi-Factor Analysis
```
1. Correlation Analysis
   - Pearson/Spearman correlation
   - VIF for multicollinearity

2. Model Building
   - Start with linear regression
   - Add interaction terms
   - Try nonlinear models (RF, XGBoost)

3. Interpretation
   - Feature importance
   - Partial dependence plots
   - SHAP values
```

### Pattern 3: Policy Impact Quantification
```
1. Baseline Scenario
   - Model without policy

2. Policy Scenario
   - Incorporate policy as variable
   - Estimate effect size

3. Comparison
   - Difference-in-differences
   - Counterfactual analysis
```

## Mathematical Notation Standards

### Variables
- Scalars: lowercase italic ($x, y, t$)
- Vectors: lowercase bold ($\mathbf{x}, \mathbf{y}$)
- Matrices: uppercase bold ($\mathbf{X}, \mathbf{Y}$)
- Sets: uppercase calligraphic ($\mathcal{X}, \mathcal{Y}$)

### Common Symbols
- Time index: $t = 1, 2, \ldots, T$
- Observations: $i = 1, 2, \ldots, n$
- Parameters: $\theta, \beta, \alpha$
- Predictions: $\hat{y}$
- Residuals: $\epsilon$

## Decision Trees

### Model Selection for Forecasting
```
Is data time series?
‚îú‚îÄ Yes: Is it stationary?
‚îÇ  ‚îú‚îÄ Yes: ARIMA
‚îÇ  ‚îî‚îÄ No: Differencing ‚Üí ARIMA or Prophet
‚îî‚îÄ No: Is relationship linear?
   ‚îú‚îÄ Yes: Linear Regression
   ‚îî‚îÄ No: Random Forest / XGBoost
```

### Validation Strategy
```
Data size?
‚îú‚îÄ Small (n < 100): Leave-one-out CV
‚îú‚îÄ Medium (100 ‚â§ n < 1000): 5-fold CV
‚îî‚îÄ Large (n ‚â• 1000): Train/validation/test split
```

## Reference: Historical Problems

### 2023 APMCM C: Electric Vehicles
**Question Types:**
- Q1: Factor analysis (what affects EV adoption)
- Q2: Trend prediction (10-year forecast)
- Q3: Impact analysis (on traditional vehicles)
- Q4: Policy impact (resistance policies)
- Q5: Environmental impact (quantification)

**Modeling Approaches Used:**
- Multiple regression for factors
- ARIMA for trend prediction
- System dynamics for market impact
- Scenario analysis for policies

### 2024 APMCM C: Pet Industry
**Question Types:**
- Q1: Trend analysis by pet type (5-year history, 3-year forecast)
- Q2: Global demand forecasting
- Q3: Production and export prediction
- Q4: Tariff policy impact

**Modeling Approaches Used:**
- Time series decomposition
- Multi-variate regression
- Elasticity analysis for tariffs
- Monte Carlo for uncertainty

## Tips

1. **Start Simple**: Begin with linear models, add complexity if needed
2. **Document Assumptions**: Every assumption must be justified
3. **Multiple Models**: Always compare 2-3 approaches
4. **Sanity Checks**: Do predictions make sense?
5. **Time Management**: Don't over-optimize, good enough is enough
